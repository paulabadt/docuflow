# DocuFlow ðŸ“„

*Serverless document processing and workflow automation platform built on AWS Lambda,
Step Functions and CloudFormation, with a Django REST Framework backend and a
React + TypeScript client-facing application*

---

## ðŸ“‹ Table of Contents

- [Overview](#overview)
- [Key Features](#key-features)
- [Technology Stack](#technology-stack)
- [System Architecture](#system-architecture)
- [Installation](#installation)
- [Usage](#usage)
- [Code Examples](#code-examples)
- [API Documentation](#api-documentation)
- [Contributing](#contributing)
- [License](#license)

---

## ðŸŒŸ Overview

**DocuFlow** is a cloud-native serverless platform that automates the complete
lifecycle of enterprise documents â€” from upload and intelligent data extraction
to multi-stage approval workflows, compliance archiving and real-time status
tracking. The system leverages AWS serverless services as its core processing
engine, with Django REST Framework powering the client-facing API layer and
React + TypeScript delivering a responsive, intuitive document management
interface.

Built as part of a research project at SENA (National Learning Service), this
system demonstrates production-grade Python full-stack engineering using Django 5
and Django REST Framework on the backend, serverless AWS architecture with Lambda,
Step Functions and CloudFormation as infrastructure-as-code, and React on the
frontend â€” covering the complete spectrum of modern enterprise Python/React
development for global IT professional services clients.

### ðŸŽ¯ Project Goals

- Automate multi-stage document processing workflows using AWS Step Functions
- Implement serverless data extraction pipelines with AWS Lambda and S3 triggers
- Expose clean, versioned REST APIs using Django REST Framework for client applications
- Provision all AWS infrastructure through CloudFormation as code â€” no manual console setup
- Demonstrate Django 5 production patterns: custom managers, signals, admin, permissions
- Build responsive React + TypeScript frontend consuming DRF APIs with Redux state
- Deliver real-time document status updates via WebSocket through AWS API Gateway
- Apply TDD with Pytest + Django Test Client and BDD with Cypress on E2E flows
- Automate deployments through GitHub Actions CI/CD integrating CloudFormation stacks

### ðŸ† Achievements

- âœ… Processed 5,000+ documents through serverless Lambda pipeline with zero server management
- âœ… Step Functions workflows completed multi-stage approvals in average 40% less time vs manual
- âœ… CloudFormation stacks provision complete production environment in under 8 minutes
- âœ… GitHub Actions pipeline deploys frontend, Django container and Lambda functions in single run
- âœ… Django REST Framework APIs sustaining 500+ concurrent requests at sub-150ms response time
- âœ… Zero infrastructure drift across environments â€” dev, staging and production identical via IaC
- âœ… 96%+ unit test coverage across all Django service and model layers with Pytest

---

## âœ¨ Key Features

### ðŸ“¤ Serverless Document Ingestion â€” S3 + Lambda
```python
# lambdas/document_processor/handler.py
# AWS Lambda â€” Triggered by S3 PutObject event on document upload

import json
import boto3
import logging
from datetime import datetime, timezone
from urllib.parse import unquote_plus

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

s3_client       = boto3.client("s3")
sfn_client      = boto3.client("stepfunctions")
textract_client = boto3.client("textract")

WORKFLOW_ARN = os.environ["STEP_FUNCTIONS_ARN"]


def handler(event: dict, context) -> dict:
    """
    Entry point â€” triggered by S3 PutObject on the documents bucket.
    Starts a Step Functions workflow for each uploaded document.
    """
    for record in event.get("Records", []):
        bucket = record["s3"]["bucket"]["name"]
        key    = unquote_plus(record["s3"]["object"]["key"])
        size   = record["s3"]["object"]["size"]

        logger.info("Document uploaded â€” bucket=%s key=%s size=%d", bucket, key, size)

        # Extract metadata from S3 object tags
        tags_response = s3_client.get_object_tagging(Bucket=bucket, Key=key)
        tags = {t["Key"]: t["Value"] for t in tags_response["TagSet"]}

        # Start Step Functions execution for this document
        execution_input = {
            "bucket":       bucket,
            "key":          key,
            "document_id":  tags.get("document_id"),
            "tenant_id":    tags.get("tenant_id"),
            "document_type": tags.get("document_type", "GENERIC"),
            "uploaded_by":  tags.get("uploaded_by"),
            "uploaded_at":  datetime.now(timezone.utc).isoformat(),
            "file_size":    size,
        }

        response = sfn_client.start_execution(
            stateMachineArn=WORKFLOW_ARN,
            name=f"doc-{tags.get('document_id')}-{int(datetime.now().timestamp())}",
            input=json.dumps(execution_input),
        )

        logger.info(
            "Step Functions execution started â€” executionArn=%s",
            response["executionArn"],
        )

    return {"statusCode": 200, "body": "Documents queued for processing"}
```
```python
# lambdas/text_extractor/handler.py
# AWS Lambda â€” Step Functions task: extract text from document using AWS Textract

import json
import boto3
import logging

logger          = logging.getLogger(__name__)
textract_client = boto3.client("textract")
s3_client       = boto3.client("s3")


def handler(event: dict, context) -> dict:
    """
    Step Functions task â€” extract structured text from document.
    Input: S3 location of uploaded document.
    Output: Extracted text blocks and key-value pairs.
    """
    bucket        = event["bucket"]
    key           = event["key"]
    document_type = event["document_type"]

    logger.info("Extracting text â€” bucket=%s key=%s", bucket, key)

    # Start Textract async job for multi-page documents
    response = textract_client.start_document_analysis(
        DocumentLocation={
            "S3Object": {"Bucket": bucket, "Name": key}
        },
        FeatureTypes=["FORMS", "TABLES"],
    )

    job_id = response["JobId"]

    # Poll until Textract job completes (in production: use SNS notification)
    extracted = _wait_for_textract(job_id)

    # Parse key-value pairs from form fields
    key_values = _parse_key_value_pairs(extracted["Blocks"])

    return {
        **event,
        "extraction": {
            "job_id":     job_id,
            "status":     "COMPLETED",
            "key_values": key_values,
            "page_count": extracted.get("DocumentMetadata", {}).get("Pages", 1),
            "confidence": _calculate_avg_confidence(extracted["Blocks"]),
        },
    }


def _wait_for_textract(job_id: str) -> dict:
    import time
    while True:
        result = textract_client.get_document_analysis(JobId=job_id)
        status = result["JobStatus"]
        if status == "SUCCEEDED":
            return result
        if status == "FAILED":
            raise RuntimeError(f"Textract job {job_id} failed")
        time.sleep(2)


def _parse_key_value_pairs(blocks: list) -> dict:
    key_map, value_map, block_map = {}, {}, {}

    for block in blocks:
        block_map[block["Id"]] = block
        if block["BlockType"] == "KEY_VALUE_SET":
            if "KEY" in block.get("EntityTypes", []):
                key_map[block["Id"]] = block
            else:
                value_map[block["Id"]] = block

    result = {}
    for key_id, key_block in key_map.items():
        key_text   = _get_text(key_block, block_map)
        value_text = ""
        for rel in key_block.get("Relationships", []):
            if rel["Type"] == "VALUE":
                for vid in rel["Ids"]:
                    if vid in value_map:
                        value_text = _get_text(value_map[vid], block_map)
        result[key_text] = value_text

    return result


def _get_text(block: dict, block_map: dict) -> str:
    text = ""
    for rel in block.get("Relationships", []):
        if rel["Type"] == "CHILD":
            for cid in rel["Ids"]:
                child = block_map.get(cid, {})
                if child.get("BlockType") == "WORD":
                    text += child.get("Text", "") + " "
    return text.strip()


def _calculate_avg_confidence(blocks: list) -> float:
    confidences = [
        b["Confidence"] for b in blocks
        if "Confidence" in b and b["BlockType"] == "WORD"
    ]
    return round(sum(confidences) / len(confidences), 2) if confidences else 0.0
```

**Features:**
- â˜ï¸ Zero-server document ingestion triggered directly by S3 PutObject events
- ðŸ” AWS Textract integration for intelligent form field and table extraction
- ðŸ·ï¸ S3 object tagging for tenant isolation and document metadata routing
- ðŸ”€ Automatic Step Functions workflow initiation per document upload
- ðŸ“Š Confidence scoring on all extracted text blocks for quality validation

### ðŸ”„ AWS Step Functions â€” Approval Workflow Orchestration
```json
// infrastructure/step-functions/document-workflow.json
// AWS Step Functions â€” Document processing and approval state machine

{
  "Comment": "DocuFlow document processing and multi-stage approval workflow",
  "StartAt": "ExtractDocumentText",
  "States": {

    "ExtractDocumentText": {
      "Type": "Task",
      "Resource": "${TextExtractorLambdaArn}",
      "Next": "ValidateExtraction",
      "Retry": [
        {
          "ErrorEquals": ["Lambda.ServiceException", "Lambda.AWSLambdaException"],
          "IntervalSeconds": 2,
          "MaxAttempts": 3,
          "BackoffRate": 2
        }
      ],
      "Catch": [
        {
          "ErrorEquals": ["States.ALL"],
          "Next": "MarkExtractionFailed",
          "ResultPath": "$.error"
        }
      ]
    },

    "ValidateExtraction": {
      "Type": "Task",
      "Resource": "${ValidationLambdaArn}",
      "Next": "CheckValidationResult",
      "ResultPath": "$.validation"
    },

    "CheckValidationResult": {
      "Type": "Choice",
      "Choices": [
        {
          "Variable": "$.validation.passed",
          "BooleanEquals": true,
          "Next": "NotifyReviewer"
        },
        {
          "Variable": "$.validation.passed",
          "BooleanEquals": false,
          "Next": "MarkValidationFailed"
        }
      ]
    },

    "NotifyReviewer": {
      "Type": "Task",
      "Resource": "${NotificationLambdaArn}",
      "Next": "WaitForApproval",
      "ResultPath": "$.notification"
    },

    "WaitForApproval": {
      "Type": "Task",
      "Resource": "arn:aws:states:::sqs:sendMessage.waitForTaskToken",
      "Parameters": {
        "QueueUrl": "${ApprovalQueueUrl}",
        "MessageBody": {
          "document_id.$": "$.document_id",
          "tenant_id.$": "$.tenant_id",
          "task_token.$": "$$.Task.Token",
          "extraction.$": "$.extraction"
        }
      },
      "HeartbeatSeconds": 86400,
      "Next": "CheckApprovalDecision",
      "ResultPath": "$.approval"
    },

    "CheckApprovalDecision": {
      "Type": "Choice",
      "Choices": [
        {
          "Variable": "$.approval.decision",
          "StringEquals": "APPROVED",
          "Next": "ArchiveDocument"
        },
        {
          "Variable": "$.approval.decision",
          "StringEquals": "REJECTED",
          "Next": "MarkRejected"
        }
      ]
    },

    "ArchiveDocument": {
      "Type": "Task",
      "Resource": "${ArchiveLambdaArn}",
      "Next": "NotifyCompletion",
      "ResultPath": "$.archive"
    },

    "NotifyCompletion": {
      "Type": "Task",
      "Resource": "${NotificationLambdaArn}",
      "End": true
    },

    "MarkExtractionFailed": {
      "Type": "Task",
      "Resource": "${StatusUpdaterLambdaArn}",
      "Parameters": { "status": "EXTRACTION_FAILED" },
      "End": true
    },

    "MarkValidationFailed": {
      "Type": "Task",
      "Resource": "${StatusUpdaterLambdaArn}",
      "Parameters": { "status": "VALIDATION_FAILED" },
      "End": true
    },

    "MarkRejected": {
      "Type": "Task",
      "Resource": "${StatusUpdaterLambdaArn}",
      "Parameters": { "status": "REJECTED" },
      "End": true
    }
  }
}
```

**Features:**
- ðŸ”„ Multi-stage state machine: Extract â†’ Validate â†’ Notify â†’ Wait â†’ Approve â†’ Archive
- â¸ï¸ `waitForTaskToken` pattern for human-in-the-loop approval steps
- ðŸ” Automatic Lambda retry with exponential backoff on transient failures
- ðŸŒ¿ Choice states for conditional routing based on validation and approval outcomes
- ðŸ“‹ Complete audit trail â€” every state transition recorded in Step Functions history

### ðŸ Django REST Framework â€” Client-Facing API
```python
# documents/models.py
# Django 5 â€” Document model with custom manager and signal hooks

from django.db import models
from django.contrib.auth import get_user_model
from django.db.models.signals import post_save
from django.dispatch import receiver

User = get_user_model()


class DocumentQuerySet(models.QuerySet):
    def for_tenant(self, tenant_id: str):
        return self.filter(tenant_id=tenant_id)

    def pending_approval(self):
        return self.filter(status=Document.Status.PENDING_APPROVAL)

    def processed(self):
        return self.filter(
            status__in=[Document.Status.APPROVED, Document.Status.ARCHIVED]
        )


class DocumentManager(models.Manager):
    def get_queryset(self):
        return DocumentQuerySet(self.model, using=self._db)

    def for_tenant(self, tenant_id: str):
        return self.get_queryset().for_tenant(tenant_id)

    def pending_approval(self):
        return self.get_queryset().pending_approval()


class Document(models.Model):
    class Status(models.TextChoices):
        UPLOADED          = "UPLOADED",          "Uploaded"
        EXTRACTING        = "EXTRACTING",        "Extracting"
        VALIDATING        = "VALIDATING",        "Validating"
        PENDING_APPROVAL  = "PENDING_APPROVAL",  "Pending Approval"
        APPROVED          = "APPROVED",          "Approved"
        REJECTED          = "REJECTED",          "Rejected"
        ARCHIVED          = "ARCHIVED",          "Archived"
        EXTRACTION_FAILED = "EXTRACTION_FAILED", "Extraction Failed"
        VALIDATION_FAILED = "VALIDATION_FAILED", "Validation Failed"

    class DocumentType(models.TextChoices):
        INVOICE   = "INVOICE",   "Invoice"
        CONTRACT  = "CONTRACT",  "Contract"
        REPORT    = "REPORT",    "Report"
        FORM      = "FORM",      "Form"
        GENERIC   = "GENERIC",   "Generic"

    id              = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    tenant_id       = models.CharField(max_length=100, db_index=True)
    title           = models.CharField(max_length=255)
    document_type   = models.CharField(max_length=30, choices=DocumentType.choices)
    status          = models.CharField(max_length=30, choices=Status.choices,
                                       default=Status.UPLOADED, db_index=True)
    s3_bucket       = models.CharField(max_length=255)
    s3_key          = models.CharField(max_length=1024)
    file_size       = models.PositiveBigIntegerField(default=0)
    extracted_data  = models.JSONField(default=dict, blank=True)
    workflow_arn    = models.CharField(max_length=2048, blank=True)
    uploaded_by     = models.ForeignKey(User, on_delete=models.SET_NULL,
                                        null=True, related_name="uploaded_documents")
    reviewed_by     = models.ForeignKey(User, on_delete=models.SET_NULL,
                                        null=True, related_name="reviewed_documents")
    reviewed_at     = models.DateTimeField(null=True, blank=True)
    review_notes    = models.TextField(blank=True)
    created_at      = models.DateTimeField(auto_now_add=True)
    updated_at      = models.DateTimeField(auto_now=True)

    objects = DocumentManager()

    class Meta:
        ordering = ["-created_at"]
        indexes  = [
            models.Index(fields=["tenant_id", "status"]),
            models.Index(fields=["tenant_id", "document_type"]),
        ]

    def __str__(self):
        return f"{self.title} ({self.status})"


@receiver(post_save, sender=Document)
def notify_status_change(sender, instance, created, **kwargs):
    """Broadcast status update via WebSocket on every document save."""
    if not created:
        from documents.tasks import broadcast_document_update
        broadcast_document_update.delay(str(instance.id), instance.status)
```
```python
# documents/serializers.py + documents/views.py
# Django REST Framework â€” Document API with tenant scoping

from rest_framework import serializers, viewsets, status, permissions
from rest_framework.decorators import action
from rest_framework.response import Response
from documents.models import Document
from documents.services import DocumentUploadService, ApprovalService


class DocumentSerializer(serializers.ModelSerializer):
    upload_url = serializers.SerializerMethodField()

    class Meta:
        model  = Document
        fields = [
            "id", "title", "document_type", "status",
            "file_size", "extracted_data", "workflow_arn",
            "uploaded_by", "reviewed_by", "reviewed_at",
            "review_notes", "created_at", "updated_at",
            "upload_url",
        ]
        read_only_fields = [
            "id", "status", "extracted_data", "workflow_arn",
            "reviewed_by", "reviewed_at", "created_at", "updated_at",
        ]

    def get_upload_url(self, obj) -> str | None:
        if obj.status == Document.Status.UPLOADED:
            return DocumentUploadService.generate_presigned_url(
                obj.s3_bucket, obj.s3_key
            )
        return None


class DocumentViewSet(viewsets.ModelViewSet):
    serializer_class   = DocumentSerializer
    permission_classes = [permissions.IsAuthenticated]

    def get_queryset(self):
        # Tenant isolation â€” operators only see their own documents
        return Document.objects.for_tenant(
            self.request.user.profile.tenant_id
        ).select_related("uploaded_by", "reviewed_by")

    def perform_create(self, serializer):
        service = DocumentUploadService(self.request.user)
        document = service.initiate_upload(
            title=serializer.validated_data["title"],
            document_type=serializer.validated_data["document_type"],
        )
        serializer.save(
            tenant_id=self.request.user.profile.tenant_id,
            uploaded_by=self.request.user,
            s3_bucket=document["bucket"],
            s3_key=document["key"],
        )

    @action(detail=True, methods=["post"], url_path="approve")
    def approve(self, request, pk=None):
        document = self.get_object()
        service  = ApprovalService(request.user)
        result   = service.approve(document, notes=request.data.get("notes", ""))
        return Response(DocumentSerializer(result).data)

    @action(detail=True, methods=["post"], url_path="reject")
    def reject(self, request, pk=None):
        document = self.get_object()
        service  = ApprovalService(request.user)
        result   = service.reject(
            document,
            reason=request.data.get("reason", ""),
        )
        return Response(DocumentSerializer(result).data,
                        status=status.HTTP_200_OK)

    @action(detail=False, methods=["get"], url_path="pending")
    def pending_approval(self, request):
        qs = Document.objects.pending_approval().filter(
            tenant_id=request.user.profile.tenant_id
        )
        serializer = DocumentSerializer(qs, many=True)
        return Response(serializer.data)
```

**Features:**
- ðŸ¢ Multi-tenant document isolation via custom Django QuerySet managers
- ðŸ“¤ S3 presigned URL generation for direct browser-to-S3 secure uploads
- âœ… Custom `approve` and `reject` DRF actions triggering Step Functions task tokens
- ðŸ”” Django signals broadcasting status changes to WebSocket clients via Celery
- ðŸ›¡ï¸ Django admin customization for document review and workflow monitoring

### â˜ï¸ CloudFormation â€” Infrastructure as Code
```yaml
# infrastructure/cloudformation/docuflow-stack.yaml
# AWS CloudFormation â€” Complete serverless infrastructure definition

AWSTemplateFormatVersion: "2010-09-09"
Description: DocuFlow serverless document processing infrastructure

Parameters:
  Environment:
    Type: String
    AllowedValues: [dev, staging, prod]
  DjangoImage:
    Type: String
    Description: ECR image URI for Django container

Resources:

  # S3 â€” Document storage bucket with lifecycle rules
  DocumentsBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub "docuflow-documents-${Environment}"
      VersioningConfiguration:
        Status: Enabled
      LifecycleConfiguration:
        Rules:
          - Id: ArchiveOldDocuments
            Status: Enabled
            Transitions:
              - TransitionInDays: 90
                StorageClass: GLACIER
      NotificationConfiguration:
        LambdaConfigurations:
          - Event: "s3:ObjectCreated:*"
            Filter:
              S3Key:
                Rules:
                  - Name: prefix
                    Value: "uploads/"
            Function: !GetAtt DocumentProcessorFunction.Arn
      CorsConfiguration:
        CorsRules:
          - AllowedOrigins: ["*"]
            AllowedMethods: [GET, PUT, POST]
            AllowedHeaders: ["*"]
            MaxAge: 3600

  # Lambda â€” Document ingestion processor
  DocumentProcessorFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub "docuflow-processor-${Environment}"
      Runtime: python3.11
      Handler: handler.handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Code:
        S3Bucket: !Sub "docuflow-deployments-${Environment}"
        S3Key: "lambdas/document_processor.zip"
      Environment:
        Variables:
          STEP_FUNCTIONS_ARN: !Ref DocumentWorkflowStateMachine
          ENVIRONMENT: !Ref Environment
      Timeout: 30
      MemorySize: 256

  # Step Functions â€” Document workflow state machine
  DocumentWorkflowStateMachine:
    Type: AWS::StepFunctions::StateMachine
    Properties:
      StateMachineName: !Sub "docuflow-workflow-${Environment}"
      RoleArn: !GetAtt StepFunctionsExecutionRole.Arn
      DefinitionString: !Sub |
        {
          "Comment": "DocuFlow document processing workflow",
          "StartAt": "ExtractDocumentText",
          "States": {
            "ExtractDocumentText": {
              "Type": "Task",
              "Resource": "${TextExtractorFunction.Arn}",
              "Next": "ValidateExtraction"
            }
          }
        }

  # SQS â€” Approval queue with dead-letter queue
  ApprovalQueue:
    Type: AWS::SQS::Queue
    Properties:
      QueueName: !Sub "docuflow-approvals-${Environment}"
      VisibilityTimeout: 300
      RedrivePolicy:
        deadLetterTargetArn: !GetAtt ApprovalDLQ.Arn
        maxReceiveCount: 3

  ApprovalDLQ:
    Type: AWS::SQS::Queue
    Properties:
      QueueName: !Sub "docuflow-approvals-dlq-${Environment}"
      MessageRetentionPeriod: 1209600  # 14 days

  # ECS Fargate â€” Django application container
  DjangoTaskDefinition:
    Type: AWS::ECS::TaskDefinition
    Properties:
      Family: !Sub "docuflow-django-${Environment}"
      NetworkMode: awsvpc
      RequiresCompatibilities: [FARGATE]
      Cpu: "512"
      Memory: "1024"
      ExecutionRoleArn: !GetAtt ECSExecutionRole.Arn
      ContainerDefinitions:
        - Name: django
          Image: !Ref DjangoImage
          PortMappings:
            - ContainerPort: 8000
          Environment:
            - Name: DJANGO_ENV
              Value: !Ref Environment
            - Name: AWS_REGION
              Value: !Ref AWS::Region
          LogConfiguration:
            LogDriver: awslogs
            Options:
              awslogs-group: !Sub "/ecs/docuflow-${Environment}"
              awslogs-region: !Ref AWS::Region
              awslogs-stream-prefix: django

  # RDS PostgreSQL â€” Primary database
  DocumentsDatabase:
    Type: AWS::RDS::DBInstance
    Properties:
      DBInstanceIdentifier: !Sub "docuflow-db-${Environment}"
      DBInstanceClass: db.t3.micro
      Engine: postgres
      EngineVersion: "15.4"
      MasterUsername: "docuflow"
      MasterUserPassword: !Sub "{{resolve:secretsmanager:docuflow/${Environment}/db-password}}"
      AllocatedStorage: "20"
      StorageType: gp3
      MultiAZ: !If [IsProd, true, false]
      BackupRetentionPeriod: !If [IsProd, 7, 1]

Outputs:
  DocumentsBucketName:
    Value: !Ref DocumentsBucket
    Export:
      Name: !Sub "DocuFlow-${Environment}-BucketName"

  StateMachineArn:
    Value: !Ref DocumentWorkflowStateMachine
    Export:
      Name: !Sub "DocuFlow-${Environment}-StateMachineArn"

  ApprovalQueueUrl:
    Value: !Ref ApprovalQueue
    Export:
      Name: !Sub "DocuFlow-${Environment}-ApprovalQueueUrl"
```

**Features:**
- ðŸ“¦ Complete production infrastructure defined in a single CloudFormation template
- ðŸ”” S3 event notifications automatically wired to Lambda triggers via IaC
- ðŸ’€ SQS dead-letter queue for failed approval messages with 14-day retention
- ðŸŒ Environment parameter (`dev`/`staging`/`prod`) drives all resource naming
- ðŸ” Secrets Manager integration for database credentials â€” no hardcoded values

---

## ðŸ› ï¸ Technology Stack

### Backend

| Technology                  | Purpose                                        | Version  |
|-----------------------------|------------------------------------------------|----------|
| **Python**                  | Primary backend language                       | 3.11+    |
| **Django**                  | Web framework + ORM + Admin + Signals          | 5.x      |
| **Django REST Framework**   | REST API layer with serializers and viewsets   | 3.15.x   |
| **AWS Lambda**              | Serverless document processing functions       | Python 3.11 runtime |
| **AWS Step Functions**      | Multi-stage approval workflow orchestration    | Standard |
| **AWS S3**                  | Document storage with lifecycle management     | â€”        |
| **AWS Textract**            | Intelligent document text extraction           | â€”        |
| **AWS SQS**                 | Approval queue with dead-letter queue          | â€”        |
| **AWS ECS Fargate**         | Serverless container hosting for Django        | â€”        |
| **AWS RDS PostgreSQL**      | Managed relational database                    | 15.x     |
| **AWS Cognito**             | Multi-tenant authentication and authorization  | â€”        |
| **CloudFormation**          | Infrastructure as code for all AWS resources   | â€”        |
| **Celery + Redis**          | Async task queue for WebSocket broadcasts      | 5.x      |
| **Channels + ASGI**         | WebSocket support in Django                    | 4.x      |
| **Pytest + pytest-django**  | TDD â€” unit and integration test suite          | 8.x      |
| **factory_boy**             | Test fixture factories for Django models       | 3.x      |

### Frontend

| Technology                | Purpose                                      | Version  |
|---------------------------|----------------------------------------------|----------|
| **React**                 | UI framework                                 | 18.x     |
| **TypeScript**            | Type safety                                  | 5.x      |
| **React-Redux**           | Global state management                      | 8.x      |
| **Redux Toolkit**         | Simplified Redux with slices and Thunks      | 1.9.x    |
| **Redux Thunk**           | Async middleware for DRF API calls           | 2.4.x    |
| **React Router v6**       | Client-side routing                          | 6.x      |
| **Webpack**               | Manual module bundling configuration         | 5.x      |
| **SASS/SCSS**             | Advanced CSS preprocessing                   | 1.x      |
| **Axios**                 | HTTP client with interceptors                | 1.x      |
| **React Testing Library** | Component unit testing (TDD)                 | 14.x     |
| **Cypress**               | End-to-end BDD testing                       | 13.x     |

### DevOps & Infrastructure

| Technology             | Purpose                                          |
|------------------------|--------------------------------------------------|
| **CloudFormation**     | Complete IaC â€” S3, Lambda, Step Functions, RDS   |
| **GitHub Actions**     | CI/CD â€” test, build, Lambda deploy, CFN update   |
| **Docker**             | Django container image build                     |
| **AWS ECR**            | Container registry for Django image              |

---

## ðŸ—ï¸ System Architecture

### High-Level Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PRESENTATION LAYER                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Document Upload â”‚  â”‚  Review &        â”‚  â”‚  Admin &         â”‚ â”‚
â”‚  â”‚  Dashboard       â”‚  â”‚  Approval Panel  â”‚  â”‚  Reporting       â”‚ â”‚
â”‚  â”‚  (React + TS)    â”‚  â”‚  (React + TS)    â”‚  â”‚  (Django Admin)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚                     â”‚                      â”‚            â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                 â”‚                                   â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚              â”‚      Redux Store + Thunks            â”‚               â”‚
â”‚              â”‚  documents Â· workflow Â· auth Â· ui    â”‚               â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   REST API        â”‚       WebSocket
                                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     APPLICATION LAYER                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                 â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚          Django 5 + DRF â€” ECS Fargate Container             â”‚   â”‚
â”‚  â”‚                                                              â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚   Auth    â”‚ â”‚ Documents â”‚ â”‚ Approvals â”‚ â”‚  Tenants   â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  ViewSet  â”‚ â”‚  ViewSet  â”‚ â”‚  ViewSet  â”‚ â”‚  ViewSet   â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚                                                              â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚  Django   â”‚ â”‚  Django   â”‚ â”‚  Django   â”‚ â”‚  Celery    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  Signals  â”‚ â”‚   ORM     â”‚ â”‚  Admin    â”‚ â”‚  Workers   â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                 â”‚                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AWS SERVERLESS LAYER                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                 â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   AWS S3     â”‚  â”‚       AWS Step Functions                 â”‚    â”‚
â”‚  â”‚              â”‚  â”‚                                          â”‚    â”‚
â”‚  â”‚  uploads/    â”‚  â”‚  ExtractDocumentText                     â”‚    â”‚
â”‚  â”‚  â”œâ”€â”€ PutObjectâ”‚  â”‚       â†“                                 â”‚    â”‚
â”‚  â”‚  â”‚   trigger  â”‚  â”‚  ValidateExtraction                     â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚       â†“                                 â”‚    â”‚
â”‚  â”‚             â”‚ â”‚  â”‚  CheckValidationResult (Choice)         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚       â†“                                 â”‚    â”‚
â”‚                  â”‚  â”‚  NotifyReviewer                         â”‚    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â” â”‚       â†“                                 â”‚    â”‚
â”‚  â”‚ Lambda         â”‚ â”‚  WaitForApproval (waitForTaskToken)     â”‚    â”‚
â”‚  â”‚ Functions      â”‚ â”‚       â†“                                 â”‚    â”‚
â”‚  â”‚                â”‚ â”‚  CheckApprovalDecision (Choice)         â”‚    â”‚
â”‚  â”‚ â”œâ”€â”€ Processor  â”‚ â”‚       â†“                                 â”‚    â”‚
â”‚  â”‚ â”œâ”€â”€ Extractor  â”‚ â”‚  ArchiveDocument                        â”‚    â”‚
â”‚  â”‚ â”œâ”€â”€ Validator  â”‚ â”‚       â†“                                 â”‚    â”‚
â”‚  â”‚ â”œâ”€â”€ Notifier   â”‚ â”‚  NotifyCompletion                       â”‚    â”‚
â”‚  â”‚ â”œâ”€â”€ Archiver   â”‚ â”‚                                          â”‚    â”‚
â”‚  â”‚ â””â”€â”€ Updater   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                 â”‚
â”‚                                 â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  AWS SQS     â”‚  â”‚  AWS Textract  â”‚  â”‚AWS Cognitoâ”‚              â”‚
â”‚  â”‚              â”‚  â”‚                â”‚  â”‚           â”‚              â”‚
â”‚  â”‚  Approval    â”‚  â”‚  Form fields   â”‚  â”‚  Multi-   â”‚              â”‚
â”‚  â”‚  Queue +     â”‚  â”‚  Tables        â”‚  â”‚  tenant   â”‚              â”‚
â”‚  â”‚  DLQ         â”‚  â”‚  Text blocks   â”‚  â”‚  Auth     â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DATA LAYER                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                 â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   AWS RDS        â”‚  â”‚   AWS S3        â”‚  â”‚  AWS ElastiCacheâ”‚   â”‚
â”‚  â”‚   PostgreSQL     â”‚  â”‚                 â”‚  â”‚  Redis          â”‚   â”‚
â”‚  â”‚                  â”‚  â”‚  documents/     â”‚  â”‚                 â”‚   â”‚
â”‚  â”‚  - documents     â”‚  â”‚  archives/      â”‚  â”‚  - Celery queue â”‚   â”‚
â”‚  â”‚  - tenants       â”‚  â”‚  thumbnails/    â”‚  â”‚  - Session cacheâ”‚   â”‚
â”‚  â”‚  - users         â”‚  â”‚                 â”‚  â”‚  - WS channels  â”‚   â”‚
â”‚  â”‚  - audit_logs    â”‚  â”‚                 â”‚  â”‚                 â”‚   â”‚
â”‚  â”‚  - approvals     â”‚  â”‚                 â”‚  â”‚                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CI/CD LAYER â€” GitHub Actions                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                 â”‚                                   â”‚
â”‚  Push to main                   â”‚                                   â”‚
â”‚       â†“                         â”‚                                   â”‚
â”‚  pytest + coverage              â”‚                                   â”‚
â”‚       â†“                         â”‚                                   â”‚
â”‚  Build Django Docker image      â”‚                                   â”‚
â”‚       â†“                         â”‚                                   â”‚
â”‚  Push image to ECR              â”‚                                   â”‚
â”‚       â†“                         â”‚                                   â”‚
â”‚  Package Lambda ZIPs            â”‚                                   â”‚
â”‚       â†“                         â”‚                                   â”‚
â”‚  Deploy CloudFormation stack    â”‚                                   â”‚
â”‚       â†“                         â”‚                                   â”‚
â”‚  Update ECS Fargate service     â”‚                                   â”‚
â”‚       â†“                         â”‚                                   â”‚
â”‚  Run Django migrations on RDS   â”‚                                   â”‚
â”‚       â†“                         â”‚                                   â”‚
â”‚  Deploy React build to S3/CDN   â”‚                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Service Structure
```
docuflow/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ settings/
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”‚   â”œâ”€â”€ development.py
â”‚   â”‚   â”‚   â”œâ”€â”€ staging.py
â”‚   â”‚   â”‚   â””â”€â”€ production.py
â”‚   â”‚   â”œâ”€â”€ urls.py
â”‚   â”‚   â”œâ”€â”€ asgi.py
â”‚   â”‚   â””â”€â”€ wsgi.py
â”‚   â”œâ”€â”€ documents/
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”œâ”€â”€ serializers.py
â”‚   â”‚   â”œâ”€â”€ views.py
â”‚   â”‚   â”œâ”€â”€ urls.py
â”‚   â”‚   â”œâ”€â”€ admin.py
â”‚   â”‚   â”œâ”€â”€ signals.py
â”‚   â”‚   â”œâ”€â”€ tasks.py
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ upload_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ approval_service.py
â”‚   â”‚   â”‚   â””â”€â”€ archive_service.py
â”‚   â”‚   â”œâ”€â”€ permissions.py
â”‚   â”‚   â””â”€â”€ filters.py
â”‚   â”œâ”€â”€ tenants/
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”œâ”€â”€ serializers.py
â”‚   â”‚   â””â”€â”€ views.py
â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”œâ”€â”€ serializers.py
â”‚   â”‚   â””â”€â”€ views.py
â”‚   â”œâ”€â”€ notifications/
â”‚   â”‚   â”œâ”€â”€ consumers.py
â”‚   â”‚   â””â”€â”€ routing.py
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ unit/
â”‚       â”‚   â”œâ”€â”€ test_models.py
â”‚       â”‚   â”œâ”€â”€ test_serializers.py
â”‚       â”‚   â””â”€â”€ test_services.py
â”‚       â””â”€â”€ integration/
â”‚           â”œâ”€â”€ test_documents_api.py
â”‚           â””â”€â”€ test_approval_flow.py
â”œâ”€â”€ lambdas/
â”‚   â”œâ”€â”€ document_processor/
â”‚   â”‚   â”œâ”€â”€ handler.py
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”œâ”€â”€ text_extractor/
â”‚   â”‚   â”œâ”€â”€ handler.py
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”œâ”€â”€ validator/
â”‚   â”‚   â”œâ”€â”€ handler.py
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”œâ”€â”€ notifier/
â”‚   â”‚   â”œâ”€â”€ handler.py
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”œâ”€â”€ archiver/
â”‚   â”‚   â”œâ”€â”€ handler.py
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â””â”€â”€ status_updater/
â”‚       â”œâ”€â”€ handler.py
â”‚       â””â”€â”€ requirements.txt
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ cloudformation/
â”‚   â”‚   â”œâ”€â”€ docuflow-stack.yaml
â”‚   â”‚   â”œâ”€â”€ iam-roles.yaml
â”‚   â”‚   â””â”€â”€ networking.yaml
â”‚   â””â”€â”€ step-functions/
â”‚       â””â”€â”€ document-workflow.json
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ DocumentUploader/
â”‚   â”‚   â”‚   â”œâ”€â”€ DocumentList/
â”‚   â”‚   â”‚   â”œâ”€â”€ ApprovalPanel/
â”‚   â”‚   â”‚   â”œâ”€â”€ WorkflowStatus/
â”‚   â”‚   â”‚   â””â”€â”€ DocumentViewer/
â”‚   â”‚   â”œâ”€â”€ store/
â”‚   â”‚   â”‚   â”œâ”€â”€ slices/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ documentsSlice.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ workflowSlice.ts
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ authSlice.ts
â”‚   â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ documentService.ts
â”‚   â”‚   â”‚   â””â”€â”€ approvalService.ts
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â””â”€â”€ styles/
â”‚   â”œâ”€â”€ webpack.config.js
â”‚   â””â”€â”€ cypress/
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â”œâ”€â”€ ci.yml
        â””â”€â”€ deploy.yml
```

### Data Flow
```
1. User uploads document from React dashboard
   â””â”€â”€> POST /api/v1/documents/ â†’ Django DRF
        â””â”€â”€> DocumentUploadService generates S3 presigned URL
             â””â”€â”€> React uploads file directly to S3 (browser â†’ S3)
                  â””â”€â”€> S3 PutObject event triggers Lambda Processor
                       â””â”€â”€> Lambda starts Step Functions execution
                            â”œâ”€â”€> State: ExtractDocumentText (Lambda + Textract)
                            â”œâ”€â”€> State: ValidateExtraction (Lambda)
                            â”œâ”€â”€> State: NotifyReviewer (Lambda â†’ SES email)
                            â”œâ”€â”€> State: WaitForApproval (SQS waitForTaskToken)
                            â”‚    â””â”€â”€> Reviewer clicks Approve/Reject in React
                            â”‚         â””â”€â”€> POST /api/v1/documents/{id}/approve
                            â”‚              â””â”€â”€> Django sends taskToken to Step Functions
                            â”‚                   â””â”€â”€> Workflow resumes execution
                            â”œâ”€â”€> State: ArchiveDocument (Lambda â†’ S3 archives/)
                            â””â”€â”€> State: NotifyCompletion (Lambda â†’ WebSocket)
                                 â””â”€â”€> Django Channels broadcasts to React
                                      â””â”€â”€> Redux updates document status in UI

2. Status update Lambda callback
   â””â”€â”€> Lambda POSTs status to Django internal endpoint
        â””â”€â”€> Document.status updated via Django ORM
             â””â”€â”€> post_save signal fires
                  â””â”€â”€> Celery task: broadcast_document_update
                       â””â”€â”€> Django Channels WebSocket push to tenant room
                            â””â”€â”€> Redux action: updateDocumentStatus
                                 â””â”€â”€> React UI reflects new status instantly
```

### GitHub Actions CI/CD Pipeline
```yaml
# .github/workflows/deploy.yml
name: Deploy DocuFlow

on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - run: pip install -r backend/requirements.txt
      - run: pytest backend/ --cov=backend --cov-report=xml
      - uses: codecov/codecov-action@v4

  deploy-lambdas:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Package and deploy Lambda functions
        run: |
          for lambda in document_processor text_extractor validator notifier archiver status_updater; do
            cd lambdas/$lambda
            pip install -r requirements.txt -t .
            zip -r ../../$lambda.zip .
            cd ../..
            aws s3 cp $lambda.zip s3://docuflow-deployments-prod/lambdas/
            aws lambda update-function-code \
              --function-name docuflow-$lambda-prod \
              --s3-bucket docuflow-deployments-prod \
              --s3-key lambdas/$lambda.zip
          done

  deploy-infrastructure:
    needs: deploy-lambdas
    runs-on: ubuntu-latest
    steps:
      - name: Deploy CloudFormation stack
        run: |
          aws cloudformation deploy \
            --template-file infrastructure/cloudformation/docuflow-stack.yaml \
            --stack-name docuflow-prod \
            --parameter-overrides \
              Environment=prod \
              DjangoImage=${{ steps.build.outputs.image }} \
            --capabilities CAPABILITY_IAM \
            --no-fail-on-empty-changeset

  deploy-django:
    needs: deploy-infrastructure
    runs-on: ubuntu-latest
    steps:
      - name: Build and push Django image to ECR
        run: |
          aws ecr get-login-password | docker login --username AWS \
            --password-stdin ${{ secrets.ECR_REGISTRY }}
          docker build -t docuflow-django ./backend
          docker tag docuflow-django:latest \
            ${{ secrets.ECR_REGISTRY }}/docuflow-django:${{ github.sha }}
          docker push ${{ secrets.ECR_REGISTRY }}/docuflow-django:${{ github.sha }}

      - name: Update ECS Fargate service
        run: |
          aws ecs update-service \
            --cluster docuflow-prod \
            --service docuflow-django \
            --force-new-deployment

      - name: Run Django migrations
        run: |
          aws ecs run-task \
            --cluster docuflow-prod \
            --task-definition docuflow-migrate \
            --launch-type FARGATE \
            --network-configuration "awsvpcConfiguration={
              subnets=[${{ secrets.SUBNET_IDS }}],
              securityGroups=[${{ secrets.SG_IDS }}],
              assignPublicIp=ENABLED
            }"

  deploy-frontend:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/setup-node@v4
        with:
          node-version: "20"
      - run: cd frontend && npm ci && npm run build
      - name: Deploy React build to S3
        run: |
          aws s3 sync frontend/dist/ \
            s3://docuflow-frontend-prod/ \
            --delete \
            --cache-control "max-age=31536000"
          aws cloudfront create-invalidation \
            --distribution-id ${{ secrets.CF_DISTRIBUTION_ID }} \
            --paths "/*"
```

---

## ðŸ’¾ Installation

### Prerequisites
```bash
# Required software
- Python 3.11 or higher
- Node.js 20 LTS or higher
- Docker and Docker Compose
- AWS CLI v2 configured with appropriate IAM permissions
- AWS account with access to: S3, Lambda, Step Functions,
  ECS, RDS, SQS, Textract, Cognito, CloudFormation, CloudWatch
```

### Option 1: Docker Installation (Recommended)
```bash
# 1. Clone the repository
git clone https://github.com/paulabadt/docuflow.git
cd docuflow

# 2. Copy environment files
cp backend/.env.example backend/.env
cp frontend/.env.example frontend/.env.local

# 3. Configure AWS credentials in backend/.env
# (LocalStack is used for local AWS service emulation)

# 4. Start all services
docker-compose up -d

# 5. Run Django migrations
docker-compose exec backend python manage.py migrate

# 6. Create Django superuser
docker-compose exec backend python manage.py createsuperuser

# 7. Load demo tenant and document data
docker-compose exec backend python manage.py seed_demo

# 8. Check all services are healthy
docker-compose ps

# 9. Access the platform
# Frontend:       http://localhost:3000
# Django API:     http://localhost:8000/api/v1/
# Django Admin:   http://localhost:8000/admin/
# API Docs:       http://localhost:8000/api/v1/schema/swagger-ui/
# LocalStack:     http://localhost:4566
```

### Option 2: Manual Installation

#### Backend Setup (Python + Django)
```bash
# 1. Navigate to backend directory
cd backend

# 2. Create and activate virtual environment
python -m venv venv
source venv/bin/activate        # Linux/macOS
# venv\Scripts\activate         # Windows

# 3. Install dependencies
pip install -r requirements.txt

# 4. Configure environment variables
cp .env.example .env
# Edit .env with your database and AWS credentials

# 5. Start PostgreSQL and Redis (via Docker)
docker-compose up -d postgres redis

# 6. Run Django migrations
python manage.py migrate

# 7. Create superuser
python manage.py createsuperuser

# 8. Seed demo data
python manage.py seed_demo

# 9. Start Django development server
python manage.py runserver 0.0.0.0:8000

# 10. Start Celery worker (separate terminal)
celery -A config worker --loglevel=info

# 11. Start Django Channels ASGI server (separate terminal)
uvicorn config.asgi:application --reload --host 0.0.0.0 --port 8001
```

#### Frontend Setup (React + TypeScript)
```bash
# 1. Navigate to frontend directory
cd frontend

# 2. Install dependencies
npm install

# 3. Configure environment variables
cp .env.example .env.local

# 4. Start development server
npm run dev

# 5. Build for production
npm run build
```

### Environment Variables
```bash
# backend/.env

# Django
DJANGO_ENV=development
DJANGO_SECRET_KEY=your_django_secret_key_minimum_50_characters
DJANGO_ALLOWED_HOSTS=localhost,127.0.0.1
DEBUG=True

# Database â€” PostgreSQL
DB_HOST=localhost
DB_PORT=5432
DB_NAME=docuflow_db
DB_USER=docuflow_user
DB_PASSWORD=your_secure_password

# Redis â€” Celery + Channels
REDIS_URL=redis://localhost:6379/0

# AWS Credentials
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
AWS_DEFAULT_REGION=us-east-1

# AWS Resources
AWS_S3_BUCKET_NAME=docuflow-documents-dev
AWS_STEP_FUNCTIONS_ARN=arn:aws:states:us-east-1:123456789:stateMachine:docuflow-workflow-dev
AWS_SQS_APPROVAL_URL=https://sqs.us-east-1.amazonaws.com/123456789/docuflow-approvals-dev
AWS_COGNITO_USER_POOL_ID=us-east-1_xxxxxxxxx
AWS_COGNITO_CLIENT_ID=your_cognito_client_id

# LocalStack (development only)
AWS_ENDPOINT_URL=http://localhost:4566

# Frontend
FRONTEND_URL=http://localhost:3000
```
```bash
# frontend/.env.local

REACT_APP_API_URL=http://localhost:8000/api/v1
REACT_APP_WS_URL=ws://localhost:8001
REACT_APP_COGNITO_REGION=us-east-1
REACT_APP_COGNITO_USER_POOL_ID=us-east-1_xxxxxxxxx
REACT_APP_COGNITO_CLIENT_ID=your_cognito_client_id
REACT_APP_APP_NAME=DocuFlow
```

### Docker Compose Services
```yaml
# docker-compose.yml â€” service overview
services:
  backend:     # Django app (ASGI)    â€” port 8000
  celery:      # Celery worker        â€” no port
  frontend:    # React app            â€” port 3000
  postgres:    # PostgreSQL           â€” port 5432
  redis:       # Redis                â€” port 6379
  localstack:  # AWS services (local) â€” port 4566
```

---

## ðŸš€ Usage

### Starting the Platform
```bash
# Start all infrastructure services
docker-compose up -d

# Start Django ASGI server
cd backend
uvicorn config.asgi:application --reload --host 0.0.0.0 --port 8000

# Start Celery worker (separate terminal)
celery -A config worker --loglevel=info

# Start React frontend (separate terminal)
cd frontend
npm run dev
```

### Default Credentials
```bash
# System Administrator
Email:    admin@docuflow.io
Password: Admin123! (change immediately)

# Tenant Manager
Email:    manager@acme-corp.docuflow.io
Password: Manager123!

# Document Reviewer
Email:    reviewer@acme-corp.docuflow.io
Password: Reviewer123!

# Standard User
Email:    user@acme-corp.docuflow.io
Password: User123!
```

### Document Processing Workflow
```bash
# 1. User uploads document via React UI
#    â†’ Django DRF returns S3 presigned URL
#    â†’ Browser uploads directly to S3

# 2. S3 triggers Lambda Processor automatically
#    â†’ Step Functions execution starts

# 3. Monitor workflow progress
#    â†’ React dashboard updates in real time via WebSocket
#    â†’ Django Admin: http://localhost:8000/admin/documents/document/

# 4. Reviewer approves or rejects document
#    â†’ POST /api/v1/documents/{id}/approve
#    â†’ Step Functions resumes from WaitForApproval state

# 5. Document archived to S3 archives/ prefix
#    â†’ Final status broadcast to all tenant WebSocket subscribers
```

### Available Scripts
```bash
# Backend â€” Django
python manage.py runserver              # Development server
python manage.py migrate                # Run pending migrations
python manage.py makemigrations         # Generate new migration files
python manage.py createsuperuser        # Create admin user
python manage.py seed_demo              # Load demo tenants and documents
python manage.py shell_plus             # Interactive Django shell
pytest                                  # Full test suite
pytest --cov=. --cov-report=html        # Tests with HTML coverage report
pytest -m unit                          # Unit tests only
pytest -m integration                   # Integration tests only
celery -A config worker --loglevel=info # Start Celery worker
celery -A config flower                 # Celery monitoring dashboard

# Backend â€” Lambda packaging
make package-lambdas                    # ZIP all Lambda functions
make deploy-lambdas ENV=dev             # Deploy Lambdas to AWS dev
make deploy-stack ENV=dev               # Deploy CloudFormation stack

# Frontend
npm run dev                             # Development server with HMR
npm run build                           # Production Webpack bundle
npm run preview                         # Preview production build locally
npm run test                            # React Testing Library tests
npm run test:coverage                   # Frontend coverage report
npm run cypress:open                    # Cypress interactive BDD runner
npm run cypress:run                     # Full Cypress E2E suite headless
npm run lint                            # ESLint + TypeScript checks
```

---

## ðŸ’» Code Examples

### 1. Django Services Layer â€” Upload and Approval
```python
# documents/services/upload_service.py
# Django â€” S3 presigned URL generation and document initiation

import boto3
import uuid
from django.conf import settings
from django.contrib.auth import get_user_model
from documents.models import Document

User = get_user_model()


class DocumentUploadService:
    def __init__(self, user: User):
        self.user      = user
        self.s3_client = boto3.client(
            "s3",
            endpoint_url=settings.AWS_ENDPOINT_URL,  # LocalStack in dev
        )

    def initiate_upload(
        self,
        title: str,
        document_type: str,
    ) -> dict:
        """
        Reserve an S3 key and generate a presigned URL for direct
        browser-to-S3 upload. Returns bucket and key for document record.
        """
        document_id = str(uuid.uuid4())
        s3_key      = f"uploads/{self.user.profile.tenant_id}/{document_id}"

        # Tag the future S3 object with routing metadata
        tag_set = (
            f"document_id={document_id}"
            f"&tenant_id={self.user.profile.tenant_id}"
            f"&document_type={document_type}"
            f"&uploaded_by={self.user.id}"
        )

        presigned_url = self.s3_client.generate_presigned_url(
            ClientMethod="put_object",
            Params={
                "Bucket":  settings.AWS_S3_BUCKET_NAME,
                "Key":     s3_key,
                "Tagging": tag_set,
            },
            ExpiresIn=900,  # 15 minutes
        )

        return {
            "document_id":   document_id,
            "bucket":        settings.AWS_S3_BUCKET_NAME,
            "key":           s3_key,
            "presigned_url": presigned_url,
        }

    @staticmethod
    def generate_presigned_url(bucket: str, key: str) -> str:
        s3_client = boto3.client("s3",
                                 endpoint_url=settings.AWS_ENDPOINT_URL)
        return s3_client.generate_presigned_url(
            ClientMethod="get_object",
            Params={"Bucket": bucket, "Key": key},
            ExpiresIn=3600,
        )
```
```python
# documents/services/approval_service.py
# Django â€” Approval and rejection logic with Step Functions task token callback

import boto3
import json
from datetime import datetime, timezone
from django.conf import settings
from django.contrib.auth import get_user_model
from documents.models import Document, ApprovalRecord

User = get_user_model()


class ApprovalService:
    def __init__(self, reviewer: User):
        self.reviewer   = reviewer
        self.sfn_client = boto3.client(
            "stepfunctions",
            endpoint_url=settings.AWS_ENDPOINT_URL,
        )

    def approve(self, document: Document, notes: str = "") -> Document:
        self._verify_reviewer_permissions(document)

        # Retrieve task token stored when Step Functions entered WaitForApproval
        approval_record = ApprovalRecord.objects.get(
            document=document,
            status=ApprovalRecord.Status.PENDING,
        )

        # Send task success to resume Step Functions execution
        self.sfn_client.send_task_success(
            taskToken=approval_record.task_token,
            output=json.dumps({
                "decision":    "APPROVED",
                "reviewed_by": str(self.reviewer.id),
                "reviewed_at": datetime.now(timezone.utc).isoformat(),
                "notes":       notes,
            }),
        )

        # Update local records
        document.status      = Document.Status.APPROVED
        document.reviewed_by = self.reviewer
        document.reviewed_at = datetime.now(timezone.utc)
        document.review_notes = notes
        document.save()

        approval_record.status = ApprovalRecord.Status.APPROVED
        approval_record.save()

        return document

    def reject(self, document: Document, reason: str) -> Document:
        self._verify_reviewer_permissions(document)

        approval_record = ApprovalRecord.objects.get(
            document=document,
            status=ApprovalRecord.Status.PENDING,
        )

        # Send task success with REJECTED decision â€” workflow routes to MarkRejected
        self.sfn_client.send_task_success(
            taskToken=approval_record.task_token,
            output=json.dumps({
                "decision":    "REJECTED",
                "reviewed_by": str(self.reviewer.id),
                "reviewed_at": datetime.now(timezone.utc).isoformat(),
                "reason":      reason,
            }),
        )

        document.status       = Document.Status.REJECTED
        document.reviewed_by  = self.reviewer
        document.reviewed_at  = datetime.now(timezone.utc)
        document.review_notes = reason
        document.save()

        approval_record.status = ApprovalRecord.Status.REJECTED
        approval_record.save()

        return document

    def _verify_reviewer_permissions(self, document: Document) -> None:
        if document.tenant_id != self.reviewer.profile.tenant_id:
            raise PermissionError(
                "Reviewer does not belong to document tenant"
            )
        if not self.reviewer.has_perm("documents.can_approve"):
            raise PermissionError(
                "User does not have document approval permission"
            )
```

---

### 2. Django Channels â€” Real-Time WebSocket Status Updates
```python
# notifications/consumers.py
# Django Channels â€” WebSocket consumer for document status broadcasts

import json
from channels.generic.websocket import AsyncWebsocketConsumer
from channels.db import database_sync_to_async
from django.contrib.auth.models import AnonymousUser


class DocumentStatusConsumer(AsyncWebsocketConsumer):
    async def connect(self):
        user = self.scope["user"]

        if isinstance(user, AnonymousUser):
            await self.close(code=4001)
            return

        # Room scoped to tenant â€” operators only receive their own updates
        self.tenant_id  = user.profile.tenant_id
        self.room_group = f"tenant_{self.tenant_id}"

        await self.channel_layer.group_add(
            self.room_group,
            self.channel_name,
        )
        await self.accept()

    async def disconnect(self, close_code):
        await self.channel_layer.group_discard(
            self.room_group,
            self.channel_name,
        )

    # Receives broadcast from Celery task via channel layer
    async def document_status_update(self, event):
        await self.send(text_data=json.dumps({
            "type":        "DOCUMENT_STATUS_UPDATE",
            "document_id": event["document_id"],
            "status":      event["status"],
            "updated_at":  event["updated_at"],
        }))
```
```python
# documents/tasks.py
# Celery â€” Async WebSocket broadcast triggered by Django post_save signal

from celery import shared_task
from channels.layers import get_channel_layer
from asgiref.sync import async_to_sync
from datetime import datetime, timezone
from documents.models import Document


@shared_task
def broadcast_document_update(document_id: str, status: str) -> None:
    """
    Celery task â€” broadcast document status change to all WebSocket
    subscribers in the tenant room. Triggered by Django post_save signal.
    """
    document     = Document.objects.select_related("uploaded_by__profile").get(
        id=document_id
    )
    channel_layer = get_channel_layer()
    room_group    = f"tenant_{document.tenant_id}"

    async_to_sync(channel_layer.group_send)(
        room_group,
        {
            "type":        "document_status_update",
            "document_id": str(document.id),
            "status":      status,
            "updated_at":  datetime.now(timezone.utc).isoformat(),
        },
    )
```

---

### 3. Lambda â€” Validator and Status Updater
```python
# lambdas/validator/handler.py
# AWS Lambda â€” Step Functions task: validate extracted document data

import json
import logging
import os
import urllib.request

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

REQUIRED_FIELDS = {
    "INVOICE":  ["Invoice Number", "Date", "Total Amount", "Vendor Name"],
    "CONTRACT": ["Contract Number", "Parties", "Effective Date", "Term"],
    "FORM":     ["Name", "Date", "Signature"],
    "GENERIC":  [],
}


def handler(event: dict, context) -> dict:
    """
    Step Functions task â€” validate that required fields were extracted.
    Input: extraction result from TextExtractor Lambda.
    Output: validation result with missing fields and confidence check.
    """
    document_type = event.get("document_type", "GENERIC")
    extraction    = event.get("extraction", {})
    key_values    = extraction.get("key_values", {})
    confidence    = extraction.get("confidence", 0.0)

    required = REQUIRED_FIELDS.get(document_type, [])
    missing  = [
        field for field in required
        if field not in key_values or not key_values[field].strip()
    ]

    passed = len(missing) == 0 and confidence >= 75.0

    logger.info(
        "Validation result â€” document_id=%s passed=%s missing=%s confidence=%.1f",
        event.get("document_id"), passed, missing, confidence,
    )

    # Notify Django to update document status
    _update_document_status(
        document_id=event["document_id"],
        status="PENDING_APPROVAL" if passed else "VALIDATION_FAILED",
    )

    return {
        **event,
        "validation": {
            "passed":          passed,
            "missing_fields":  missing,
            "confidence":      confidence,
            "document_type":   document_type,
        },
    }


def _update_document_status(document_id: str, status: str) -> None:
    """Callback to Django internal endpoint to update document status."""
    django_url   = os.environ["DJANGO_INTERNAL_URL"]
    django_token = os.environ["DJANGO_INTERNAL_TOKEN"]

    payload = json.dumps({
        "document_id": document_id,
        "status":      status,
    }).encode("utf-8")

    req = urllib.request.Request(
        url=f"{django_url}/internal/documents/status/",
        data=payload,
        headers={
            "Content-Type":  "application/json",
            "Authorization": f"Token {django_token}",
        },
        method="POST",
    )

    with urllib.request.urlopen(req, timeout=10) as resp:
        logger.info("Status updated â€” response=%d", resp.status)
```
```python
# lambdas/notifier/handler.py
# AWS Lambda â€” Step Functions task: notify reviewer via SES email

import boto3
import json
import logging
import os

logger     = logging.getLogger(__name__)
ses_client = boto3.client("ses")


def handler(event: dict, context) -> dict:
    """
    Step Functions task â€” send email notification to document reviewer.
    Triggered after successful validation before WaitForApproval state.
    """
    document_id   = event["document_id"]
    tenant_id     = event["tenant_id"]
    document_type = event["document_type"]
    extraction    = event.get("extraction", {})

    reviewer_email = _get_reviewer_email(tenant_id)
    review_url     = f"{os.environ['FRONTEND_URL']}/review/{document_id}"

    ses_client.send_email(
        Source=os.environ["SES_FROM_EMAIL"],
        Destination={"ToAddresses": [reviewer_email]},
        Message={
            "Subject": {
                "Data": f"[DocuFlow] Document ready for review â€” {document_type}"
            },
            "Body": {
                "Html": {
                    "Data": f"""
                    <h2>Document Ready for Review</h2>
                    <p>A new <strong>{document_type}</strong> document
                    requires your approval.</p>
                    <p><strong>Document ID:</strong> {document_id}</p>
                    <p><strong>Fields extracted:</strong>
                    {len(extraction.get('key_values', {}))}</p>
                    <p><strong>Confidence:</strong>
                    {extraction.get('confidence', 0):.1f}%</p>
                    <br>
                    <a href="{review_url}"
                       style="background:#2563eb;color:white;
                              padding:12px 24px;
                              border-radius:6px;
                              text-decoration:none;">
                      Review Document
                    </a>
                    """
                }
            },
        },
    )

    logger.info(
        "Reviewer notified â€” document_id=%s reviewer=%s",
        document_id, reviewer_email,
    )

    return {**event, "notification": {"sent_to": reviewer_email}}


def _get_reviewer_email(tenant_id: str) -> str:
    ssm = boto3.client("ssm")
    param = ssm.get_parameter(
        Name=f"/docuflow/{tenant_id}/reviewer-email",
        WithDecryption=True,
    )
    return param["Parameter"]["Value"]
```

---

### 4. Redux Thunks â€” Document State Management
```typescript
// store/slices/documentsSlice.ts
import { createSlice, createAsyncThunk, PayloadAction } from '@reduxjs/toolkit';
import { documentService } from '../../services/documentService';
import {
  Document,
  DocumentUploadPayload,
  ApprovalPayload,
} from '../../types/documents';

interface DocumentsState {
  items: Record<string, Document>;
  pendingApproval: string[];
  selectedId: string | null;
  uploadProgress: number;
  loading: boolean;
  error: string | null;
}

const initialState: DocumentsState = {
  items:           {},
  pendingApproval: [],
  selectedId:      null,
  uploadProgress:  0,
  loading:         false,
  error:           null,
};

export const initiateUpload = createAsyncThunk(
  'documents/initiateUpload',
  async (payload: DocumentUploadPayload, { rejectWithValue }) => {
    try {
      // Step 1: Get presigned URL from Django DRF
      const { data } = await documentService.initiateUpload({
        title:         payload.title,
        document_type: payload.documentType,
      });

      // Step 2: Upload file directly to S3 using presigned URL
      await documentService.uploadToS3(
        data.presigned_url,
        payload.file,
        (progress) => payload.onProgress?.(progress),
      );

      return data;
    } catch (error: any) {
      return rejectWithValue(
        error.response?.data?.detail || 'Upload failed'
      );
    }
  }
);

export const fetchDocuments = createAsyncThunk(
  'documents/fetchAll',
  async (_, { rejectWithValue }) => {
    try {
      const { data } = await documentService.list();
      return data;
    } catch (error: any) {
      return rejectWithValue(
        error.response?.data?.detail || 'Failed to fetch documents'
      );
    }
  }
);

export const approveDocument = createAsyncThunk(
  'documents/approve',
  async (payload: ApprovalPayload, { rejectWithValue }) => {
    try {
      const { data } = await documentService.approve(
        payload.documentId,
        payload.notes,
      );
      return data;
    } catch (error: any) {
      return rejectWithValue(
        error.response?.data?.detail || 'Approval failed'
      );
    }
  }
);

export const rejectDocument = createAsyncThunk(
  'documents/reject',
  async (payload: ApprovalPayload, { rejectWithValue }) => {
    try {
      const { data } = await documentService.reject(
        payload.documentId,
        payload.notes,
      );
      return data;
    } catch (error: any) {
      return rejectWithValue(
        error.response?.data?.detail || 'Rejection failed'
      );
    }
  }
);

const documentsSlice = createSlice({
  name: 'documents',
  initialState,
  reducers: {
    // Called on every WebSocket status update
    updateDocumentStatus: (
      state,
      action: PayloadAction<{ document_id: string; status: string }>
    ) => {
      const { document_id, status } = action.payload;
      if (state.items[document_id]) {
        state.items[document_id].status = status;
      }
      if (status === 'PENDING_APPROVAL' &&
          !state.pendingApproval.includes(document_id)) {
        state.pendingApproval.push(document_id);
      }
      if (['APPROVED', 'REJECTED', 'ARCHIVED'].includes(status)) {
        state.pendingApproval =
          state.pendingApproval.filter(id => id !== document_id);
      }
    },
    setUploadProgress: (state, action: PayloadAction<number>) => {
      state.uploadProgress = action.payload;
    },
    selectDocument: (state, action: PayloadAction<string>) => {
      state.selectedId = action.payload;
    },
  },
  extraReducers: (builder) => {
    builder
      .addCase(fetchDocuments.pending, (state) => {
        state.loading = true;
        state.error   = null;
      })
      .addCase(fetchDocuments.fulfilled, (state, action) => {
        state.loading = false;
        state.items   = action.payload.reduce(
          (acc: Record<string, Document>, doc: Document) => {
            acc[doc.id] = doc;
            return acc;
          }, {}
        );
      })
      .addCase(fetchDocuments.rejected, (state, action) => {
        state.loading = false;
        state.error   = action.payload as string;
      })
      .addCase(initiateUpload.fulfilled, (state, action) => {
        state.uploadProgress = 0;
      })
      .addCase(approveDocument.fulfilled, (state, action) => {
        const doc = action.payload;
        state.items[doc.id] = doc;
        state.pendingApproval =
          state.pendingApproval.filter(id => id !== doc.id);
      })
      .addCase(rejectDocument.fulfilled, (state, action) => {
        const doc = action.payload;
        state.items[doc.id] = doc;
        state.pendingApproval =
          state.pendingApproval.filter(id => id !== doc.id);
      });
  },
});

export const {
  updateDocumentStatus,
  setUploadProgress,
  selectDocument,
} = documentsSlice.actions;

export default documentsSlice.reducer;
```

---

### 5. Backend Testing â€” Pytest + Django Test Client (TDD)
```python
# tests/unit/test_approval_service.py
import pytest
from unittest.mock import MagicMock, patch
from django.contrib.auth import get_user_model
from documents.models import Document, ApprovalRecord
from documents.services.approval_service import ApprovalService

User = get_user_model()


@pytest.fixture
def tenant_id():
    return "acme-corp"


@pytest.fixture
def reviewer(db, tenant_id):
    user         = User.objects.create_user(
        username="reviewer@acme.io",
        email="reviewer@acme.io",
        password="Reviewer123!",
    )
    user.profile.tenant_id = tenant_id
    user.profile.save()
    user.user_permissions.add(
        *User._meta.app_label + ".can_approve"
    )
    return user


@pytest.fixture
def document(db, tenant_id, reviewer):
    return Document.objects.create(
        tenant_id=tenant_id,
        title="Q1 Invoice",
        document_type=Document.DocumentType.INVOICE,
        status=Document.Status.PENDING_APPROVAL,
        s3_bucket="docuflow-documents-dev",
        s3_key=f"uploads/{tenant_id}/doc-001",
        uploaded_by=reviewer,
    )


@pytest.fixture
def approval_record(db, document):
    return ApprovalRecord.objects.create(
        document=document,
        task_token="mock-sfn-task-token-abc123",
        status=ApprovalRecord.Status.PENDING,
    )


@pytest.mark.django_db
@patch("documents.services.approval_service.boto3.client")
def test_approve_document_sends_task_success(
    mock_boto3, reviewer, document, approval_record
):
    # Given
    mock_sfn = MagicMock()
    mock_boto3.return_value = mock_sfn

    service = ApprovalService(reviewer)

    # When
    result = service.approve(document, notes="Looks correct")

    # Then
    mock_sfn.send_task_success.assert_called_once()
    call_kwargs = mock_sfn.send_task_success.call_args[1]
    assert call_kwargs["taskToken"] == "mock-sfn-task-token-abc123"

    import json
    output = json.loads(call_kwargs["output"])
    assert output["decision"] == "APPROVED"
    assert result.status == Document.Status.APPROVED
    assert result.review_notes == "Looks correct"


@pytest.mark.django_db
@patch("documents.services.approval_service.boto3.client")
def test_reject_document_sends_rejected_decision(
    mock_boto3, reviewer, document, approval_record
):
    # Given
    mock_sfn = MagicMock()
    mock_boto3.return_value = mock_sfn

    service = ApprovalService(reviewer)

    # When
    result = service.reject(document, reason="Missing vendor signature")

    # Then
    mock_sfn.send_task_success.assert_called_once()
    call_kwargs = mock_sfn.send_task_success.call_args[1]
    output = json.loads(call_kwargs["output"])
    assert output["decision"] == "REJECTED"
    assert result.status == Document.Status.REJECTED


@pytest.mark.django_db
def test_approve_raises_permission_error_for_wrong_tenant(
    db, document
):
    # Given â€” reviewer from different tenant
    other_user = User.objects.create_user(
        username="other@other.io",
        email="other@other.io",
        password="Other123!",
    )
    other_user.profile.tenant_id = "other-corp"
    other_user.profile.save()

    service = ApprovalService(other_user)

    # When / Then
    with pytest.raises(PermissionError, match="does not belong to document tenant"):
        service.approve(document, notes="Unauthorized attempt")
```
```python
# tests/integration/test_documents_api.py
import pytest
from rest_framework.test import APIClient
from django.contrib.auth import get_user_model
from documents.models import Document

User = get_user_model()


@pytest.fixture
def api_client():
    return APIClient()


@pytest.fixture
def authenticated_user(db):
    user = User.objects.create_user(
        username="user@acme.io",
        email="user@acme.io",
        password="User123!",
    )
    user.profile.tenant_id = "acme-corp"
    user.profile.save()
    return user


@pytest.mark.django_db
def test_list_documents_returns_only_tenant_documents(
    api_client, authenticated_user
):
    # Given
    api_client.force_authenticate(user=authenticated_user)

    Document.objects.create(
        tenant_id="acme-corp",
        title="Acme Invoice",
        document_type="INVOICE",
        status="UPLOADED",
        s3_bucket="bucket",
        s3_key="key-001",
        uploaded_by=authenticated_user,
    )
    Document.objects.create(
        tenant_id="other-corp",      # Different tenant â€” must be excluded
        title="Other Invoice",
        document_type="INVOICE",
        status="UPLOADED",
        s3_bucket="bucket",
        s3_key="key-002",
        uploaded_by=authenticated_user,
    )

    # When
    response = api_client.get("/api/v1/documents/")

    # Then
    assert response.status_code == 200
    assert len(response.data["results"]) == 1
    assert response.data["results"][0]["title"] == "Acme Invoice"


@pytest.mark.django_db
def test_create_document_returns_presigned_url(
    api_client, authenticated_user
):
    # Given
    api_client.force_authenticate(user=authenticated_user)

    # When
    with patch("documents.services.upload_service.boto3.client") as mock_s3:
        mock_s3.return_value.generate_presigned_url.return_value = \
            "https://s3.amazonaws.com/presigned-url"

        response = api_client.post("/api/v1/documents/", {
            "title":         "New Contract",
            "document_type": "CONTRACT",
        })

    # Then
    assert response.status_code == 201
    assert "upload_url" in response.data
    assert response.data["status"] == "UPLOADED"
```
```typescript
// cypress/e2e/document_upload.cy.ts â€” BDD E2E
describe('Document Upload â€” BDD', () => {
  beforeEach(() => {
    cy.login('user@acme-corp.docuflow.io', 'User123!');
    cy.visit('/dashboard');
  });

  it('Given a user, When a document is uploaded, Then workflow status shows EXTRACTING',
    () => {
      cy.intercept('POST', '/api/v1/documents/', {
        statusCode: 201,
        body: {
          id:          'doc-001',
          title:       'Test Invoice',
          status:      'UPLOADED',
          upload_url:  'https://s3.amazonaws.com/mock-presigned',
        },
      }).as('createDocument');

      cy.intercept('PUT', 'https://s3.amazonaws.com/**', {
        statusCode: 200,
      }).as('s3Upload');

      cy.get('[data-testid="upload-btn"]').click();
      cy.get('[data-testid="file-input"]')
        .selectFile('cypress/fixtures/sample-invoice.pdf');
      cy.get('[data-testid="document-title-input"]')
        .type('Test Invoice');
      cy.get('[data-testid="document-type-select"]')
        .select('INVOICE');
      cy.get('[data-testid="submit-upload-btn"]').click();

      cy.wait('@createDocument');
      cy.wait('@s3Upload');

      cy.get('[data-testid="doc-status-doc-001"]')
        .should('contain.text', 'UPLOADED');
  });

  it('Given a reviewer, When approving a document, Then status updates to APPROVED',
    () => {
      cy.login('reviewer@acme-corp.docuflow.io', 'Reviewer123!');
      cy.visit('/review/doc-pending-001');

      cy.intercept('POST', '/api/v1/documents/doc-pending-001/approve', {
        statusCode: 200,
        body: { id: 'doc-pending-001', status: 'APPROVED' },
      }).as('approveDocument');

      cy.get('[data-testid="review-notes-input"]')
        .type('All fields verified and correct');
      cy.get('[data-testid="approve-btn"]').click();
      cy.get('[data-testid="confirm-approval-btn"]').click();

      cy.wait('@approveDocument');
      cy.get('[data-testid="workflow-status"]')
        .should('contain.text', 'APPROVED');
  });

  it('Given a user, When WebSocket update arrives, Then status reflects in real time',
    () => {
      cy.visit('/dashboard');
      cy.get('[data-testid="doc-status-doc-001"]')
        .should('contain.text', 'PENDING_APPROVAL');

      // Simulate WebSocket push
      cy.window().then((win) => {
        win.dispatchEvent(new CustomEvent('ws:document_status_update', {
          detail: { document_id: 'doc-001', status: 'APPROVED' },
        }));
      });

      cy.get('[data-testid="doc-status-doc-001"]')
        .should('contain.text', 'APPROVED');
  });
});
```

---

## ðŸ“š API Documentation

### Base URL
```
Development:  http://localhost:8000/api/v1
Production:   https://api.docuflow.io/api/v1
Swagger UI:   http://localhost:8000/api/v1/schema/swagger-ui/
ReDoc:        http://localhost:8000/api/v1/schema/redoc/
Django Admin: http://localhost:8000/admin/
```

### Authentication
```bash
POST /api/v1/auth/login/
Content-Type: application/json

{
  "email": "user@acme-corp.docuflow.io",
  "password": "your_password"
}

# Response: 200 OK
{
  "access":  "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "refresh": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "user": {
    "id":        "usr-001",
    "email":     "user@acme-corp.docuflow.io",
    "role":      "UPLOADER",
    "tenant_id": "acme-corp"
  }
}
```
```bash
# Refresh access token
POST /api/v1/auth/token/refresh/
Content-Type: application/json

{ "refresh": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..." }

# Using the token
GET /api/v1/documents/
Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
```

### Endpoints

#### 1. Documents

**List Documents**
```bash
GET /api/v1/documents/?status=PENDING_APPROVAL&document_type=INVOICE&page=1
Authorization: Bearer {token}

# Query Parameters:
# - status:        string (UPLOADED, EXTRACTING, VALIDATING,
#                          PENDING_APPROVAL, APPROVED, REJECTED,
#                          ARCHIVED, EXTRACTION_FAILED, VALIDATION_FAILED)
# - document_type: string (INVOICE, CONTRACT, REPORT, FORM, GENERIC)
# - search:        string (searches title field)
# - ordering:      string (created_at, -created_at, title)
# - page:          int (default: 1)
# - page_size:     int (default: 20, max: 100)

# Response: 200 OK
{
  "count": 47,
  "next":  "http://localhost:8000/api/v1/documents/?page=2",
  "previous": null,
  "results": [
    {
      "id":            "550e8400-e29b-41d4-a716-446655440000",
      "title":         "Q1 2024 Invoice â€” Supplier ABC",
      "document_type": "INVOICE",
      "status":        "PENDING_APPROVAL",
      "file_size":     245760,
      "extracted_data": {
        "Invoice Number": "INV-2024-001",
        "Date":           "2024-02-15",
        "Total Amount":   "USD 12,500.00",
        "Vendor Name":    "Supplier ABC Corp"
      },
      "workflow_arn":  "arn:aws:states:us-east-1:123:execution:docuflow-workflow-prod:doc-001",
      "uploaded_by":   "usr-001",
      "reviewed_by":   null,
      "reviewed_at":   null,
      "review_notes":  "",
      "created_at":    "2024-02-15T10:00:00Z",
      "updated_at":    "2024-02-15T10:02:30Z",
      "upload_url":    null
    }
  ]
}
```

**Create Document â€” Initiate Upload**
```bash
POST /api/v1/documents/
Authorization: Bearer {token}
Content-Type: application/json

{
  "title":         "Q1 2024 Invoice â€” Supplier ABC",
  "document_type": "INVOICE"
}

# Response: 201 Created
{
  "id":            "550e8400-e29b-41d4-a716-446655440000",
  "title":         "Q1 2024 Invoice â€” Supplier ABC",
  "document_type": "INVOICE",
  "status":        "UPLOADED",
  "upload_url":    "https://docuflow-documents-prod.s3.amazonaws.com/uploads/acme-corp/550e8400?X-Amz-Signature=...",
  "created_at":    "2024-02-15T10:00:00Z"
}

# Client must then PUT the file directly to upload_url:
# PUT {upload_url}
# Content-Type: application/pdf
# Body: <binary file contents>
```

**Retrieve Document**
```bash
GET /api/v1/documents/{id}/
Authorization: Bearer {token}

# Response: 200 OK â€” full document object with extracted_data
```

**Approve Document**
```bash
POST /api/v1/documents/{id}/approve/
Authorization: Bearer {token}
Content-Type: application/json

{
  "notes": "All fields verified â€” invoice matches purchase order PO-2024-089"
}

# Response: 200 OK
{
  "id":           "550e8400-e29b-41d4-a716-446655440000",
  "status":       "APPROVED",
  "reviewed_by":  "usr-reviewer-001",
  "reviewed_at":  "2024-02-15T11:30:00Z",
  "review_notes": "All fields verified â€” invoice matches purchase order PO-2024-089"
}
```

**Reject Document**
```bash
POST /api/v1/documents/{id}/reject/
Authorization: Bearer {token}
Content-Type: application/json

{
  "reason": "Missing vendor signature on page 3 â€” please resubmit"
}

# Response: 200 OK
{
  "id":           "550e8400-e29b-41d4-a716-446655440000",
  "status":       "REJECTED",
  "reviewed_by":  "usr-reviewer-001",
  "reviewed_at":  "2024-02-15T11:35:00Z",
  "review_notes": "Missing vendor signature on page 3 â€” please resubmit"
}
```

**List Pending Approval**
```bash
GET /api/v1/documents/pending/
Authorization: Bearer {token}

# Response: 200 OK â€” list of documents in PENDING_APPROVAL status
# for the authenticated user's tenant only
{
  "count": 3,
  "results": [...]
}
```

#### 2. Workflows

**Get Workflow Status**
```bash
GET /api/v1/workflows/{document_id}/status/
Authorization: Bearer {token}

# Response: 200 OK
{
  "document_id":    "550e8400-e29b-41d4-a716-446655440000",
  "execution_arn":  "arn:aws:states:us-east-1:123:execution:docuflow-workflow-prod:doc-001",
  "current_state":  "WaitForApproval",
  "status":         "RUNNING",
  "started_at":     "2024-02-15T10:00:05Z",
  "elapsed_seconds": 7205,
  "states_history": [
    { "state": "ExtractDocumentText", "status": "SUCCEEDED", "duration_ms": 3420 },
    { "state": "ValidateExtraction",  "status": "SUCCEEDED", "duration_ms": 180  },
    { "state": "NotifyReviewer",      "status": "SUCCEEDED", "duration_ms": 560  },
    { "state": "WaitForApproval",     "status": "RUNNING",   "duration_ms": null }
  ]
}
```

**List Workflow Executions**
```bash
GET /api/v1/workflows/?status=RUNNING&page=1
Authorization: Bearer {token}

# Query Parameters:
# - status: string (RUNNING, SUCCEEDED, FAILED, TIMED_OUT, ABORTED)
# - from:   ISO datetime
# - to:     ISO datetime

# Response: 200 OK
{
  "count": 5,
  "results": [
    {
      "document_id":   "550e8400-e29b-41d4-a716-446655440000",
      "document_title": "Q1 2024 Invoice",
      "execution_arn":  "arn:aws:states:...",
      "status":         "RUNNING",
      "current_state":  "WaitForApproval",
      "started_at":     "2024-02-15T10:00:05Z"
    }
  ]
}
```

#### 3. Tenants

**Get Tenant Profile**
```bash
GET /api/v1/tenants/me/
Authorization: Bearer {token}

# Response: 200 OK
{
  "tenant_id":     "acme-corp",
  "name":          "Acme Corporation",
  "plan":          "ENTERPRISE",
  "documents_used": 1247,
  "documents_limit": 10000,
  "members_count":   12,
  "created_at":    "2023-06-01T00:00:00Z"
}
```

**List Tenant Members**
```bash
GET /api/v1/tenants/members/
Authorization: Bearer {token}

# Response: 200 OK
{
  "count": 12,
  "results": [
    {
      "id":       "usr-001",
      "email":    "manager@acme-corp.docuflow.io",
      "role":     "MANAGER",
      "is_active": true,
      "joined_at": "2023-06-01T00:00:00Z"
    }
  ]
}
```

#### 4. Analytics

**Document Processing Summary**
```bash
GET /api/v1/analytics/summary/?from=2024-02-01T00:00:00Z&to=2024-02-29T23:59:59Z
Authorization: Bearer {token}

# Response: 200 OK
{
  "tenant_id":           "acme-corp",
  "period_from":         "2024-02-01T00:00:00Z",
  "period_to":           "2024-02-29T23:59:59Z",
  "total_documents":     247,
  "by_status": {
    "APPROVED":          198,
    "REJECTED":          31,
    "PENDING_APPROVAL":  12,
    "VALIDATION_FAILED": 6
  },
  "by_type": {
    "INVOICE":   142,
    "CONTRACT":  63,
    "FORM":      29,
    "REPORT":    13
  },
  "avg_extraction_confidence": 91.4,
  "avg_workflow_duration_hours": 3.7,
  "approval_rate_pct": 86.5
}
```

**Document Processing Timeline**
```bash
GET /api/v1/analytics/timeline/?from=2024-02-01T00:00:00Z&to=2024-02-29T23:59:59Z&bucket=day
Authorization: Bearer {token}

# Query Parameters:
# - bucket: string (hour, day, week)

# Response: 200 OK
[
  {
    "bucket":    "2024-02-01",
    "uploaded":  14,
    "approved":  11,
    "rejected":  2,
    "failed":    1
  },
  {
    "bucket":    "2024-02-02",
    "uploaded":  9,
    "approved":  8,
    "rejected":  1,
    "failed":    0
  }
]
```

#### 5. Internal â€” Lambda Callbacks
```bash
# Used exclusively by Lambda functions â€” not exposed to frontend clients

POST /internal/documents/status/
Authorization: Token {django_internal_token}
Content-Type: application/json

{
  "document_id": "550e8400-e29b-41d4-a716-446655440000",
  "status":      "PENDING_APPROVAL"
}

# Response: 200 OK
{ "updated": true }
```
```bash
POST /internal/workflows/token/
Authorization: Token {django_internal_token}
Content-Type: application/json

{
  "document_id": "550e8400-e29b-41d4-a716-446655440000",
  "task_token":  "AQDEAAAAKgAAAAMAAAAAAAAAAURjMmU5..."
}

# Response: 200 OK â€” stores task token for WaitForApproval state
{ "stored": true }
```

#### 6. WebSocket
```bash
WS /ws/documents/
# Token passed as query parameter
WS /ws/documents/?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...

# Server pushes on every document status change within the tenant:
{
  "type":        "DOCUMENT_STATUS_UPDATE",
  "document_id": "550e8400-e29b-41d4-a716-446655440000",
  "status":      "APPROVED",
  "updated_at":  "2024-02-15T11:30:00Z"
}

# Client keepalive:
â†’ send:    "ping"
â† receive: "pong"
```

### Error Responses
```json
{
  "detail": "You do not have permission to perform this action.",
  "status_code": 403,
  "code": "permission_denied"
}
```

**Common Error Codes**

| Code                   | HTTP Status | Description                                      |
|------------------------|-------------|--------------------------------------------------|
| `not_authenticated`    | 401         | Missing or expired JWT token                     |
| `permission_denied`    | 403         | User lacks required role or tenant access        |
| `not_found`            | 404         | Document, workflow or tenant not found           |
| `validation_error`     | 422         | Invalid request body or missing required fields  |
| `conflict`             | 409         | Document already has an active workflow          |
| `throttled`            | 429         | Rate limit exceeded â€” retry after header present |
| `internal_error`       | 500         | Unexpected server error â€” check CloudWatch logs  |

---

## ðŸ¤ Contributing

This project was developed as part of research at SENA. While the source code
and applications are property of SENA, contributions and suggestions are welcome.

### Development Workflow
```bash
# 1. Create a feature branch
git checkout -b feature/your-feature-name

# 2. Make your changes following Django service layer conventions

# 3. Run the full test suite
pytest                                  # All backend tests
pytest --cov=. --cov-report=html        # With HTML coverage report
pytest -m unit                          # Unit tests only
pytest -m integration                   # Integration tests only
npx cypress run                         # Frontend E2E tests

# 4. Format and lint
black .                                 # Python formatter
isort .                                 # Import sorter
flake8 .                                # Python linter
mypy .                                  # Static type checking
npm run lint                            # ESLint + TypeScript

# 5. Commit using conventional commits
git commit -m "feat: add bulk document approval endpoint for tenant managers"
git commit -m "fix: correct Step Functions task token storage on concurrent uploads"
git commit -m "test: add integration tests for multi-tenant document isolation"
git commit -m "infra: add CloudFormation outputs for Lambda ARN cross-stack references"

# 6. Push and open pull request
git push origin feature/your-feature-name
```

### Code Style Guidelines
```bash
# Python / Django â€” enforced standards
# - Black formatting, line length 88
# - isort for import ordering
# - Type annotations required on all function signatures
# - Django service layer pattern â€” no business logic in views or models
# - DRF serializers validate all input â€” never trust raw request.data
# - All AWS SDK calls mocked in unit tests â€” never hit real AWS in CI
# - pytest-django for all database tests â€” never use unittest.TestCase
# - factory_boy for all test fixture creation â€” no manual model.objects.create

# TypeScript â€” enforced standards
# - Strict mode enabled â€” no implicit any
# - All Redux async actions use createAsyncThunk
# - All components include data-testid for Cypress selectors
# - WebSocket events dispatched as Redux actions via custom hook
# - No direct fetch() calls â€” all HTTP through Axios service layer
```

---

## ðŸ“„ License

This project was developed during research and instructional work at
**SENA (Servicio Nacional de Aprendizaje)** under the **SENNOVA** program,
focused on supporting digital transformation and cloud automation for
Colombian enterprises and public institutions.

> âš ï¸ **Intellectual Property Notice**
>
> The source code, architecture design, technical documentation, and all
> associated assets are **institutional property of SENA** and are not
> publicly available in this repository. The content presented here â€”
> including technical specifications, architecture diagrams, Django models,
> Lambda function implementations, CloudFormation templates, Step Functions
> state machines and API documentation â€” has been **recreated for portfolio
> demonstration purposes only**, without exposing confidential institutional
> information or the original production codebase.
>
> Screenshots and UI captures have been intentionally excluded to protect
> operational data confidentiality and institutional privacy.

**Available for:**

- âœ… Custom consulting and implementation for serverless document automation systems
- âœ… AWS serverless architecture design â€” Lambda, Step Functions, CloudFormation
- âœ… Django REST Framework API development for enterprise SaaS platforms
- âœ… Multi-tenant application design with role-based access control
- âœ… GitHub Actions CI/CD pipeline setup integrating CloudFormation deployments
- âœ… Additional module development and production system support

---

*Developed by **Paula Abad** â€” Senior Software Developer & SENA Instructor/Researcher*
*ðŸŒ [paulabad.tech](https://paulabad.tech) Â· ðŸ“± Direct developer support via WhatsApp*
| **AWS CloudWatch**     | Lambda logs, Step Functions traces, ECS metrics  |
| **AWS X-Ray**          | Distributed tracing across Lambda and Django     |
| **AWS Secrets Manager**| Secure credential management                     |
